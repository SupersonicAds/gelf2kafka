#!/usr/bin/env ruby

require 'optparse'
require 'gelfd'
require 'yaml'
require 'hash_symbolizer'
require 'schash'
require 'socket'
require 'logger'
require 'diplomat'
require 'kafka'

$stdout.sync = true

Thread.abort_on_exception = true

@config = nil

loglevels = {
  :debug => Logger::DEBUG,
  :info => Logger::INFO,
  :warn => Logger::WARN,
  :error => Logger::Error,
  :fatal => Logger::FATAL,
  :unknown => Logger::UNKNOWN
}

@loglevel = Logger::INFO

opts = OptionParser.new
opts.banner = "Usage: #{$0} [options]"
opts.on( '--config PATH', String, 'Path to settings config' ) { |c| @config = c }
opts.on( '--log-level [LEVEL]', [:debug, :info, :warn, :error, :fatal, :unknown] ) { |l| @loglevel = loglevels[l] }
opts.on( '-h', '--help', 'Display this screen' ) { puts opts; exit 0 }
opts.parse!

unless @config
  puts opts
  exit 1
end

@logger = Logger.new(STDOUT)
@logger.level = @loglevel

@settings = YAML.load_file(@config).symbolize_keys(true)

validator = Schash::Validator.new do
  {
    gelfd: {
      host: string,
      port: integer
    },
    kafka: {
      topic: string,
      brokers: optional(string),
      consul_service: optional(string),
      consul_tag: optional(string),
      batch_size: optional(integer),
      connect_timeout: optional(integer),
      socket_timeout: optional(integer),
      max_buffer_size: optional(integer),
      delivery_threshold: optional(integer),
      delivery_interval: optional(integer)
    }
  }
end

unless validator.validate(@settings).empty?
  @logger.error("ERROR: bad settings")
  @logger.error(validator.validate(@settings))
  exit 1
end

if not @settings[:kafka][:brokers] and not @settings[:kafka][:consul_service]
  @logger.error("ERROR: nither brokers nor consul_service was specified")
  exit 1
end

@gelfd_host = @settings[:gelfd][:host]
@gelfd_port = @settings[:gelfd][:port]
@topic = @settings[:kafka][:topic]

def kafka_connect
  if @settings[:kafka].has_key?(:brokers)
    kafka_nodes = @settings[:kafka][:brokers]
  else
    kafka_nodes = Diplomat::Service.get(@settings[:kafka][:consul_service], :all, {:tag => @settings[:kafka][:consul_tag]}).inject([]) {|hosts,h| hosts << "#{h.Node}:#{h.ServicePort}"; hosts}
  end
  @kafka = Kafka.new(
    seed_brokers: kafka_nodes,
    logger: @logger,
    connect_timeout: @settings[:kafka].has_key?(:socket_timeout) ? @settings[:kafka][:socket_timeout] : 10,
    socket_timeout: @settings[:kafka].has_key?(:socket_timeout) ? @settings[:kafka][:socket_timeout] : 60
  )
  @producer = @kafka.async_producer(
    required_acks: 0,
    max_retries: 2,
    retry_backoff: 1,
    max_buffer_size: @settings[:kafka].has_key?(:max_buffer_size) ?  @settings[:kafka][:max_buffer_size] : 10000,
    delivery_threshold: @settings[:kafka].has_key?(:delivery_threshold) ? @settings[:kafka][:delivery_threshold] : 100,
    delivery_interval: @settings[:kafka].has_key?(:delivery_interval) ? @settings[:kafka][:delivery_interval] : 5,
    compression_codec: :snappy,
  )
end

def gelfd
  server = UDPSocket.new
  @logger.info("binding gelfd to #{@gelfd_host}:#{@gelfd_port}")
  server.bind(@gelfd_host, @gelfd_port)

  loop do
    data, addr = server.recvfrom(8192)
    begin
      res = Gelfd::Parser.parse(data)
      unless res.nil?
        begin
          @producer.produce(res.strip, topic: @topic)
        rescue => e
          @logger.error("Got #{e.message} while trying to produce messages to kafka aborting ...")
          exit 1
        end
      end
    rescue Exception => e
      @logger.warn("Failed parsing gelf message: #{e.message}")
    end
  end
end

kafka_connect
gelfd
